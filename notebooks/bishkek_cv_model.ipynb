{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bishkek Real Estate: Multimodal Price Prediction\n",
    "## Computer Vision + Tabular Features\n",
    "\n",
    "This notebook implements a multimodal approach combining:\n",
    "- **Tabular features**: 39 engineered features (POI distances, building attributes, etc.)\n",
    "- **Image embeddings**: ResNet-50 features from property photos\n",
    "- **Ensemble model**: XGBoost + LightGBM + CatBoost with Optuna tuning\n",
    "\n",
    "### Research Foundation\n",
    "Based on state-of-the-art papers:\n",
    "- [MHPP (arXiv 2024)](https://arxiv.org/abs/2409.05335): +21-26% MAE improvement with images\n",
    "- [PLOS One 2025](https://pmc.ncbi.nlm.nih.gov/articles/PMC12088074/): ResNet-101 + t-SNE, R\u00b2 0.809\u21920.821\n",
    "- [NBER Study](https://www.nber.org/papers/w25174): Images explain 11.7% of price variance\n",
    "- Zillow Neural Zestimate: CNN for quality detection, +20% accuracy\n",
    "\n",
    "### Expected Improvement\n",
    "| Metric | Baseline (Tabular) | Target (Multimodal) |\n",
    "|--------|-------------------|---------------------|\n",
    "| MedAPE | 5.49% | 4.0-4.5% |\n",
    "| R\u00b2 | 0.76 | 0.80-0.82 |\n",
    "| MAE | $121.71/m\u00b2 | $100-110/m\u00b2 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import gc\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "from dataclasses import dataclass\n",
    "from math import radians, sin, cos, sqrt, atan2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ML imports\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Boosting models\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "# Optuna for hyperparameter tuning\n",
    "try:\n",
    "    import optuna\n",
    "    optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "    OPTUNA_AVAILABLE = True\n",
    "except ImportError:\n",
    "    OPTUNA_AVAILABLE = False\n",
    "    print(\"Optuna not available - using default hyperparameters\")\n",
    "\n",
    "# PyTorch for image processing\n",
    "try:\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import torchvision.models as models\n",
    "    import torchvision.transforms as transforms\n",
    "    from PIL import Image\n",
    "\n",
    "    TORCH_AVAILABLE = True\n",
    "    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"PyTorch available, device: {DEVICE}\")\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"  GPU: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"  Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "except ImportError:\n",
    "    TORCH_AVAILABLE = False\n",
    "    DEVICE = None\n",
    "    print(\"PyTorch not available - image features disabled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    \"\"\"Configuration for the multimodal model\"\"\"\n",
    "    # Data paths (adjust for Kaggle vs local)\n",
    "    IS_KAGGLE = 'KAGGLE_KERNEL_RUN_TYPE' in os.environ\n",
    "\n",
    "    if IS_KAGGLE:\n",
    "        DATA_DIR = Path('/kaggle/input/bishkek-real-estate-2025')\n",
    "        CSV_PATH = DATA_DIR / 'listings.csv'\n",
    "        IMAGES_DIR = DATA_DIR / 'images'\n",
    "    else:\n",
    "        # HuggingFace dataset\n",
    "        DATA_DIR = Path('/Users/admin/PycharmProjects/real-estate-valuation/data/hf_bishkek_dataset')\n",
    "        CSV_PATH = DATA_DIR / 'listings.csv'\n",
    "        IMAGES_DIR = Path('/Users/admin/PycharmProjects/real-estate-valuation/data/images/bishkek')\n",
    "\n",
    "    # Image processing\n",
    "    IMAGE_SIZE = 224\n",
    "    BATCH_SIZE = 32\n",
    "    IMAGE_EMBEDDING_DIM = 2048  # ResNet-50 output\n",
    "    PCA_COMPONENTS = 64  # Reduced dimension for final features\n",
    "    MAX_IMAGES_PER_LISTING = 10  # Limit to avoid memory issues\n",
    "\n",
    "    # Model training\n",
    "    TEST_SIZE = 0.2\n",
    "    RANDOM_STATE = 42\n",
    "    N_OPTUNA_TRIALS = 30\n",
    "    CV_FOLDS = 5\n",
    "\n",
    "    # Target\n",
    "    TARGET_COL = 'price_per_m2'\n",
    "\n",
    "config = Config()\n",
    "print(f\"Running on: {'Kaggle' if config.IS_KAGGLE else 'Local'}\")\n",
    "print(f\"Data dir: {config.DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. POI (Points of Interest) Data\n",
    "Coordinates of key locations in Bishkek for distance-based features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POI Bishkek - key locations by category\n",
    "BISHKEK_POI = {\n",
    "    'bazaars': [\n",
    "        ('osh_bazaar', 42.874823, 74.569599),\n",
    "        ('dordoi_bazaar', 42.939732, 74.620613),\n",
    "        ('ortosay_bazaar', 42.836209, 74.615931),\n",
    "        ('alamedin_bazaar', 42.88683, 74.637305),\n",
    "    ],\n",
    "    'parks': [\n",
    "        ('dubovy_park', 42.877681, 74.606759),\n",
    "        ('ataturk_park', 42.839587, 74.595725),\n",
    "        ('karagach_grove', 42.900362, 74.619652),\n",
    "        ('victory_park', 42.826531, 74.604411),\n",
    "        ('botanical_garden', 42.857152, 74.590671),\n",
    "    ],\n",
    "    'malls': [\n",
    "        ('bishkek_park', 42.875029, 74.590403),\n",
    "        ('dordoi_plaza', 42.874685, 74.618469),\n",
    "        ('vefa_center', 42.857078, 74.609628),\n",
    "        ('tsum', 42.876813, 74.61499),\n",
    "    ],\n",
    "    'universities': [\n",
    "        ('auca', 42.81132, 74.627743),\n",
    "        ('krsu', 42.874862, 74.627114),\n",
    "        ('bhu', 42.850424, 74.585821),\n",
    "        ('knu', 42.8822, 74.586638),\n",
    "    ],\n",
    "    'hospitals': [\n",
    "        ('national_hospital', 42.869973, 74.596739),\n",
    "        ('city_hospital', 42.876149, 74.5619),\n",
    "    ],\n",
    "    'transport': [\n",
    "        ('west_bus_station', 42.873213, 74.406103),\n",
    "        ('east_bus_station', 42.887128, 74.62894),\n",
    "        ('railway_station', 42.864179, 74.605693),\n",
    "    ],\n",
    "    'admin': [\n",
    "        ('jogorku_kenesh', 42.876814, 74.600155),\n",
    "        ('ala_too_square', 42.875039, 74.603604),\n",
    "        ('erkindik_boulevard', 42.864402, 74.605287),\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Premium zones - central expensive areas\n",
    "BISHKEK_PREMIUM_ZONES = {\n",
    "    'golden_square': (42.8688, 74.6033),\n",
    "    'voentorg': (42.8722, 74.5941),\n",
    "    'railway_area': (42.8650, 74.6070),\n",
    "    'mossovet': (42.8700, 74.6117),\n",
    "}\n",
    "\n",
    "# City center\n",
    "BISHKEK_CENTER = (42.8746, 74.5698)  # Ala-Too Square\n",
    "\n",
    "\n",
    "def haversine_distance(lat1: float, lon1: float, lat2: float, lon2: float) -> float:\n",
    "    \"\"\"Calculate distance between two points on Earth (in km)\"\"\"\n",
    "    R = 6371  # Earth radius in km\n",
    "    lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1-a))\n",
    "    return R * c\n",
    "\n",
    "\n",
    "def get_min_distance_to_category(lat: float, lon: float, category: str) -> float:\n",
    "    \"\"\"Get minimum distance to any POI in category\"\"\"\n",
    "    if category not in BISHKEK_POI:\n",
    "        return np.nan\n",
    "    distances = [haversine_distance(lat, lon, poi[1], poi[2])\n",
    "                 for poi in BISHKEK_POI[category]]\n",
    "    return min(distances) if distances else np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data() -> pd.DataFrame:\n",
    "    \"\"\"Load and prepare the dataset\"\"\"\n",
    "    print(\"Loading data...\")\n",
    "\n",
    "    # Try different data sources\n",
    "    if config.IS_KAGGLE:\n",
    "        # Kaggle dataset\n",
    "        df = pd.read_csv(config.CSV_PATH)\n",
    "    else:\n",
    "        # Try HuggingFace first\n",
    "        try:\n",
    "            from huggingface_hub import hf_hub_download\n",
    "            csv_path = hf_hub_download(\n",
    "                repo_id=\"raimbekovm/bishkek-real-estate\",\n",
    "                filename=\"data/bishkek_apartments.csv\",\n",
    "                repo_type=\"dataset\"\n",
    "            )\n",
    "            df = pd.read_csv(csv_path)\n",
    "            print(\"Loaded from HuggingFace\")\n",
    "        except:\n",
    "            # Fall back to local\n",
    "            df = pd.read_csv(config.CSV_PATH)\n",
    "            print(\"Loaded from local file\")\n",
    "\n",
    "    print(f\"Dataset: {len(df)} listings, {len(df.columns)} columns\")\n",
    "    return df\n",
    "\n",
    "\n",
    "df = load_data()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabularFeatureEngineer:\n",
    "    \"\"\"\n",
    "    Feature engineering pipeline for tabular data.\n",
    "    Creates 39 features from raw listing data.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.feature_names = []\n",
    "        self.target_encoders = {}\n",
    "\n",
    "    def fit_transform(self, df: pd.DataFrame, is_train: bool = True) -> pd.DataFrame:\n",
    "        \"\"\"Apply all feature engineering steps\"\"\"\n",
    "        df = df.copy()\n",
    "\n",
    "        # 1. Basic features\n",
    "        df = self._create_basic_features(df)\n",
    "\n",
    "        # 2. Building features\n",
    "        df = self._create_building_features(df)\n",
    "\n",
    "        # 3. Apartment features\n",
    "        df = self._create_apartment_features(df)\n",
    "\n",
    "        # 4. POI distance features\n",
    "        df = self._create_poi_features(df)\n",
    "\n",
    "        # 5. Target encoding (fit on train only)\n",
    "        if is_train:\n",
    "            df = self._fit_target_encoding(df)\n",
    "        else:\n",
    "            df = self._transform_target_encoding(df)\n",
    "\n",
    "        return df\n",
    "\n",
    "    def _create_basic_features(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Basic numeric features\"\"\"\n",
    "        # Core features\n",
    "        df['rooms'] = pd.to_numeric(df.get('rooms', 0), errors='coerce').fillna(2)\n",
    "        df['area'] = pd.to_numeric(df.get('area', 0), errors='coerce').fillna(50)\n",
    "        df['floor'] = pd.to_numeric(df.get('floor', 0), errors='coerce').fillna(1)\n",
    "        df['total_floors'] = pd.to_numeric(df.get('total_floors', 0), errors='coerce').fillna(5)\n",
    "\n",
    "        # Derived features\n",
    "        df['floor_ratio'] = df['floor'] / df['total_floors'].replace(0, 1)\n",
    "        df['area_per_room'] = df['area'] / df['rooms'].replace(0, 1)\n",
    "        df['is_first_floor'] = (df['floor'] == 1).astype(int)\n",
    "        df['is_last_floor'] = (df['floor'] == df['total_floors']).astype(int)\n",
    "\n",
    "        return df\n",
    "\n",
    "    def _create_building_features(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Building type and age features\"\"\"\n",
    "        # Year built\n",
    "        current_year = 2026\n",
    "        df['year_built'] = pd.to_numeric(df.get('year_built', 0), errors='coerce')\n",
    "        df['year_built'] = df['year_built'].apply(\n",
    "            lambda x: x if 1950 <= x <= current_year else np.nan\n",
    "        )\n",
    "        df['building_age'] = current_year - df['year_built'].fillna(current_year - 20)\n",
    "\n",
    "        # Building type flags\n",
    "        house_type = df.get('house_type', '').fillna('').str.lower()\n",
    "        df['is_monolith'] = house_type.str.contains('\u043c\u043e\u043d\u043e\u043b\u0438\u0442', na=False).astype(int)\n",
    "        df['is_brick'] = house_type.str.contains('\u043a\u0438\u0440\u043f\u0438\u0447', na=False).astype(int)\n",
    "        df['is_panel'] = house_type.str.contains('\u043f\u0430\u043d\u0435\u043b\u044c', na=False).astype(int)\n",
    "\n",
    "        # Building categories\n",
    "        df['is_new_building'] = (df['building_age'] <= 5).astype(int)\n",
    "        df['is_soviet'] = (df['building_age'] >= 30).astype(int)\n",
    "        df['is_highrise'] = (df['total_floors'] >= 9).astype(int)\n",
    "\n",
    "        return df\n",
    "\n",
    "    def _create_apartment_features(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Apartment-specific features\"\"\"\n",
    "        # Kitchen and living area\n",
    "        df['kitchen_area'] = pd.to_numeric(df.get('kitchen_area', 0), errors='coerce').fillna(0)\n",
    "        df['living_area'] = pd.to_numeric(df.get('living_area', 0), errors='coerce').fillna(0)\n",
    "\n",
    "        df['kitchen_ratio'] = df['kitchen_area'] / df['area'].replace(0, 1)\n",
    "        df['living_ratio'] = df['living_area'] / df['area'].replace(0, 1)\n",
    "\n",
    "        # Ceiling height\n",
    "        df['ceiling_height'] = pd.to_numeric(df.get('ceiling_height', 0), errors='coerce')\n",
    "        df['ceiling_height'] = df['ceiling_height'].apply(\n",
    "            lambda x: x if 2.0 <= x <= 4.5 else np.nan\n",
    "        ).fillna(2.7)\n",
    "\n",
    "        # Condition score\n",
    "        condition_map = {\n",
    "            '\u0447\u0435\u0440\u043d\u043e\u0432\u0430\u044f': 1, '\u043f\u0440\u0435\u0434\u0447\u0438\u0441\u0442\u043e\u0432\u0430\u044f': 2, '\u0442\u0440\u0435\u0431\u0443\u0435\u0442 \u0440\u0435\u043c\u043e\u043d\u0442\u0430': 3,\n",
    "            '\u0441\u0440\u0435\u0434\u043d\u0438\u0439 \u0440\u0435\u043c\u043e\u043d\u0442': 4, '\u0445\u043e\u0440\u043e\u0448\u0438\u0439 \u0440\u0435\u043c\u043e\u043d\u0442': 5,\n",
    "            '\u0435\u0432\u0440\u043e\u0440\u0435\u043c\u043e\u043d\u0442': 6, '\u0434\u0438\u0437\u0430\u0439\u043d\u0435\u0440\u0441\u043a\u0438\u0439': 7\n",
    "        }\n",
    "        df['condition_score'] = df.get('condition', '').map(condition_map).fillna(4)\n",
    "\n",
    "        # Amenities (binary features)\n",
    "        for col in ['balcony', 'parking', 'furniture', 'internet', 'security']:\n",
    "            if col in df.columns:\n",
    "                df[f'has_{col}'] = df[col].notna().astype(int)\n",
    "            else:\n",
    "                df[f'has_{col}'] = 0\n",
    "\n",
    "        return df\n",
    "\n",
    "    def _create_poi_features(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Distance to Points of Interest\"\"\"\n",
    "        # Ensure coordinates exist\n",
    "        df['latitude'] = pd.to_numeric(df.get('latitude', 0), errors='coerce')\n",
    "        df['longitude'] = pd.to_numeric(df.get('longitude', 0), errors='coerce')\n",
    "\n",
    "        # Fill missing coordinates with city center\n",
    "        df['latitude'] = df['latitude'].apply(\n",
    "            lambda x: x if 42.7 <= x <= 43.0 else BISHKEK_CENTER[0]\n",
    "        )\n",
    "        df['longitude'] = df['longitude'].apply(\n",
    "            lambda x: x if 74.3 <= x <= 74.8 else BISHKEK_CENTER[1]\n",
    "        )\n",
    "\n",
    "        # Distance to city center\n",
    "        df['dist_to_center'] = df.apply(\n",
    "            lambda r: haversine_distance(r['latitude'], r['longitude'],\n",
    "                                        BISHKEK_CENTER[0], BISHKEK_CENTER[1]),\n",
    "            axis=1\n",
    "        )\n",
    "\n",
    "        # Distance to POI categories\n",
    "        for category in BISHKEK_POI.keys():\n",
    "            df[f'dist_to_{category}'] = df.apply(\n",
    "                lambda r: get_min_distance_to_category(r['latitude'], r['longitude'], category),\n",
    "                axis=1\n",
    "            )\n",
    "\n",
    "        # Premium zone features\n",
    "        premium_distances = []\n",
    "        for _, coords in BISHKEK_PREMIUM_ZONES.items():\n",
    "            dist = df.apply(\n",
    "                lambda r: haversine_distance(r['latitude'], r['longitude'], coords[0], coords[1]),\n",
    "                axis=1\n",
    "            )\n",
    "            premium_distances.append(dist)\n",
    "\n",
    "        df['dist_to_premium'] = pd.concat(premium_distances, axis=1).min(axis=1)\n",
    "        df['is_premium_zone'] = (df['dist_to_premium'] <= 1.0).astype(int)\n",
    "\n",
    "        return df\n",
    "\n",
    "    def _fit_target_encoding(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Fit and apply target encoding for categorical features\"\"\"\n",
    "        target = config.TARGET_COL\n",
    "\n",
    "        # District encoding\n",
    "        if 'district' in df.columns and target in df.columns:\n",
    "            district_means = df.groupby('district')[target].mean()\n",
    "            global_mean = df[target].mean()\n",
    "            self.target_encoders['district'] = district_means.to_dict()\n",
    "            self.target_encoders['district_global'] = global_mean\n",
    "            df['district_encoded'] = df['district'].map(district_means).fillna(global_mean)\n",
    "\n",
    "        # Residential complex encoding\n",
    "        if 'residential_complex' in df.columns and target in df.columns:\n",
    "            jk_means = df.groupby('residential_complex')[target].mean()\n",
    "            self.target_encoders['jk'] = jk_means.to_dict()\n",
    "            df['jk_encoded'] = df['residential_complex'].map(jk_means).fillna(global_mean)\n",
    "            df['has_jk'] = df['residential_complex'].notna().astype(int)\n",
    "        else:\n",
    "            df['jk_encoded'] = df.get(target, 1500)\n",
    "            df['has_jk'] = 0\n",
    "\n",
    "        return df\n",
    "\n",
    "    def _transform_target_encoding(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Apply pre-fitted target encoding\"\"\"\n",
    "        if 'district' in self.target_encoders:\n",
    "            global_mean = self.target_encoders['district_global']\n",
    "            df['district_encoded'] = df['district'].map(\n",
    "                self.target_encoders['district']\n",
    "            ).fillna(global_mean)\n",
    "\n",
    "        if 'jk' in self.target_encoders:\n",
    "            df['jk_encoded'] = df.get('residential_complex', '').map(\n",
    "                self.target_encoders['jk']\n",
    "            ).fillna(self.target_encoders['district_global'])\n",
    "            df['has_jk'] = df.get('residential_complex', '').notna().astype(int)\n",
    "\n",
    "        return df\n",
    "\n",
    "    def get_feature_columns(self) -> List[str]:\n",
    "        \"\"\"Return list of feature columns for model training\"\"\"\n",
    "        return [\n",
    "            # Basic (8)\n",
    "            'rooms', 'area', 'floor', 'total_floors',\n",
    "            'floor_ratio', 'area_per_room', 'is_first_floor', 'is_last_floor',\n",
    "            # Building (6)\n",
    "            'building_age', 'is_monolith', 'is_brick', 'is_panel',\n",
    "            'is_new_building', 'is_soviet', 'is_highrise',\n",
    "            # Apartment (9)\n",
    "            'kitchen_ratio', 'living_ratio', 'ceiling_height', 'condition_score',\n",
    "            'has_balcony', 'has_parking', 'has_furniture', 'has_internet', 'has_security',\n",
    "            # POI (10)\n",
    "            'dist_to_center', 'dist_to_bazaars', 'dist_to_parks', 'dist_to_malls',\n",
    "            'dist_to_universities', 'dist_to_hospitals', 'dist_to_transport',\n",
    "            'dist_to_admin', 'dist_to_premium', 'is_premium_zone',\n",
    "            # Encoding (3)\n",
    "            'district_encoded', 'jk_encoded', 'has_jk',\n",
    "            # Coordinates (2)\n",
    "            'latitude', 'longitude',\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Image Feature Extraction\n",
    "\n",
    "Using ResNet-50 pretrained on ImageNet to extract visual features.\n",
    "Based on research showing images explain 11.7% of price variance (NBER)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageFeatureExtractor:\n",
    "    \"\"\"\n",
    "    Extract image embeddings using pretrained ResNet-50.\n",
    "\n",
    "    Research basis:\n",
    "    - MHPP (arXiv 2024): CLIP+ResNet50 \u2192 21-26% MAE improvement\n",
    "    - PLOS One 2025: ResNet-101 + t-SNE \u2192 R\u00b2 +1.5%\n",
    "    - Zillow: CNN for quality detection \u2192 +20% accuracy\n",
    "\n",
    "    Architecture:\n",
    "    - ResNet-50 pretrained on ImageNet\n",
    "    - Remove classification head \u2192 2048-dim embeddings\n",
    "    - Mean pooling across multiple images per listing\n",
    "    - PCA reduction \u2192 64 dimensions\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, pca_components: int = 64, batch_size: int = 32):\n",
    "        self.pca_components = pca_components\n",
    "        self.batch_size = batch_size\n",
    "        self.pca = None\n",
    "        self.model = None\n",
    "        self.transform = None\n",
    "\n",
    "        if TORCH_AVAILABLE:\n",
    "            self._setup_model()\n",
    "\n",
    "    def _setup_model(self):\n",
    "        \"\"\"Initialize ResNet-50 for feature extraction\"\"\"\n",
    "        print(\"Loading ResNet-50...\")\n",
    "\n",
    "        # Load pretrained ResNet-50\n",
    "        resnet = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)\n",
    "\n",
    "        # Remove classification head, keep up to avgpool\n",
    "        # Output: 2048-dimensional feature vector\n",
    "        self.model = nn.Sequential(*list(resnet.children())[:-1])\n",
    "        self.model.eval()\n",
    "        self.model.to(DEVICE)\n",
    "\n",
    "        # Freeze weights\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # Standard ImageNet preprocessing\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225]\n",
    "            )\n",
    "        ])\n",
    "\n",
    "        print(f\"Model loaded on {DEVICE}\")\n",
    "\n",
    "    def extract_batch(self, image_paths: List[Path]) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Extract embeddings for a batch of images.\n",
    "        Returns: (N, 2048) array of embeddings\n",
    "        \"\"\"\n",
    "        if not TORCH_AVAILABLE or self.model is None:\n",
    "            return np.zeros((len(image_paths), config.IMAGE_EMBEDDING_DIM))\n",
    "\n",
    "        embeddings = []\n",
    "        batch_tensors = []\n",
    "        valid_indices = []\n",
    "\n",
    "        for i, path in enumerate(image_paths):\n",
    "            try:\n",
    "                img = Image.open(path).convert('RGB')\n",
    "                tensor = self.transform(img)\n",
    "                batch_tensors.append(tensor)\n",
    "                valid_indices.append(i)\n",
    "                img.close()  # Explicitly close to free memory\n",
    "            except Exception as e:\n",
    "                continue\n",
    "\n",
    "        if not batch_tensors:\n",
    "            return np.zeros((len(image_paths), config.IMAGE_EMBEDDING_DIM))\n",
    "\n",
    "        # Stack and process batch\n",
    "        batch = torch.stack(batch_tensors).to(DEVICE)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            features = self.model(batch)\n",
    "            features = features.squeeze(-1).squeeze(-1)  # Remove spatial dims\n",
    "\n",
    "        # Move to CPU and convert to numpy\n",
    "        batch_embeddings = features.cpu().numpy()\n",
    "\n",
    "        # Create full array with zeros for failed images\n",
    "        result = np.zeros((len(image_paths), config.IMAGE_EMBEDDING_DIM))\n",
    "        for j, idx in enumerate(valid_indices):\n",
    "            result[idx] = batch_embeddings[j]\n",
    "\n",
    "        # Clear CUDA cache periodically\n",
    "        if DEVICE.type == 'cuda':\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        return result\n",
    "\n",
    "    def extract_listing_embedding(\n",
    "        self,\n",
    "        listing_id: str,\n",
    "        images_dir: Path,\n",
    "        max_images: int = 10\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Extract mean embedding for all images of a listing.\n",
    "\n",
    "        Strategy: Mean pooling (based on MHPP research)\n",
    "        - Robust to varying number of images per listing\n",
    "        - Captures overall property appearance\n",
    "        \"\"\"\n",
    "        listing_dir = images_dir / str(listing_id)\n",
    "\n",
    "        if not listing_dir.exists():\n",
    "            return np.zeros(config.IMAGE_EMBEDDING_DIM)\n",
    "\n",
    "        # Get image paths (limit to max_images)\n",
    "        image_paths = sorted(listing_dir.glob(\"*.jpg\"))[:max_images]\n",
    "\n",
    "        if not image_paths:\n",
    "            return np.zeros(config.IMAGE_EMBEDDING_DIM)\n",
    "\n",
    "        # Extract embeddings for all images\n",
    "        embeddings = self.extract_batch(image_paths)\n",
    "\n",
    "        # Filter out zero embeddings (failed images)\n",
    "        valid_mask = embeddings.sum(axis=1) != 0\n",
    "        valid_embeddings = embeddings[valid_mask]\n",
    "\n",
    "        if len(valid_embeddings) == 0:\n",
    "            return np.zeros(config.IMAGE_EMBEDDING_DIM)\n",
    "\n",
    "        # Mean pooling across all images\n",
    "        return np.mean(valid_embeddings, axis=0)\n",
    "\n",
    "    def extract_all_listings(\n",
    "        self,\n",
    "        listing_ids: List[str],\n",
    "        images_dir: Path,\n",
    "        show_progress: bool = True\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Extract embeddings for all listings.\n",
    "        Returns: (N_listings, 2048) array\n",
    "        \"\"\"\n",
    "        print(f\"Extracting embeddings for {len(listing_ids)} listings...\")\n",
    "\n",
    "        embeddings = []\n",
    "        iterator = tqdm(listing_ids, desc=\"Extracting images\") if show_progress else listing_ids\n",
    "\n",
    "        for i, listing_id in enumerate(iterator):\n",
    "            emb = self.extract_listing_embedding(\n",
    "                listing_id,\n",
    "                images_dir,\n",
    "                max_images=config.MAX_IMAGES_PER_LISTING\n",
    "            )\n",
    "            embeddings.append(emb)\n",
    "\n",
    "            # Clear memory every 500 listings\n",
    "            if i > 0 and i % 500 == 0:\n",
    "                gc.collect()\n",
    "                if DEVICE is not None and DEVICE.type == 'cuda':\n",
    "                    torch.cuda.empty_cache()\n",
    "\n",
    "        return np.array(embeddings)\n",
    "\n",
    "    def fit_pca(self, embeddings: np.ndarray) -> 'ImageFeatureExtractor':\n",
    "        \"\"\"Fit PCA on training embeddings\"\"\"\n",
    "        print(f\"Fitting PCA: {embeddings.shape[1]} \u2192 {self.pca_components} dimensions\")\n",
    "\n",
    "        # Filter out all-zero embeddings for PCA fitting\n",
    "        valid_mask = embeddings.sum(axis=1) != 0\n",
    "        valid_embeddings = embeddings[valid_mask]\n",
    "\n",
    "        if len(valid_embeddings) < self.pca_components:\n",
    "            print(f\"Warning: Only {len(valid_embeddings)} valid embeddings, reducing PCA components\")\n",
    "            self.pca_components = max(10, len(valid_embeddings) // 2)\n",
    "\n",
    "        self.pca = PCA(n_components=self.pca_components, random_state=42)\n",
    "        self.pca.fit(valid_embeddings)\n",
    "\n",
    "        explained_var = self.pca.explained_variance_ratio_.sum()\n",
    "        print(f\"PCA explained variance: {explained_var:.1%}\")\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform_pca(self, embeddings: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Apply PCA transformation\"\"\"\n",
    "        if self.pca is None:\n",
    "            raise ValueError(\"PCA not fitted. Call fit_pca first.\")\n",
    "        return self.pca.transform(embeddings)\n",
    "\n",
    "    def fit_transform_pca(self, embeddings: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Fit and transform in one step\"\"\"\n",
    "        self.fit_pca(embeddings)\n",
    "        return self.transform_pca(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(y_true: np.ndarray, y_pred: np.ndarray) -> Dict[str, float]:\n",
    "    \"\"\"Calculate comprehensive evaluation metrics\"\"\"\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "    # Percentage errors\n",
    "    ape = np.abs((y_true - y_pred) / y_true) * 100\n",
    "    mape = np.mean(ape)\n",
    "    medape = np.median(ape)\n",
    "\n",
    "    # Within X% accuracy\n",
    "    within_5 = (ape <= 5).mean() * 100\n",
    "    within_10 = (ape <= 10).mean() * 100\n",
    "    within_20 = (ape <= 20).mean() * 100\n",
    "\n",
    "    return {\n",
    "        'MAE': mae,\n",
    "        'RMSE': rmse,\n",
    "        'R2': r2,\n",
    "        'MAPE': mape,\n",
    "        'MedAPE': medape,\n",
    "        'Within_5%': within_5,\n",
    "        'Within_10%': within_10,\n",
    "        'Within_20%': within_20,\n",
    "    }\n",
    "\n",
    "\n",
    "def print_metrics(metrics: Dict[str, float], title: str = \"Results\"):\n",
    "    \"\"\"Pretty print metrics\"\"\"\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\" {title}\")\n",
    "    print('='*50)\n",
    "    print(f\"  MAE:      ${metrics['MAE']:.2f}/m\u00b2\")\n",
    "    print(f\"  RMSE:     ${metrics['RMSE']:.2f}/m\u00b2\")\n",
    "    print(f\"  R\u00b2:       {metrics['R2']:.4f}\")\n",
    "    print(f\"  MAPE:     {metrics['MAPE']:.2f}%\")\n",
    "    print(f\"  MedAPE:   {metrics['MedAPE']:.2f}%\")\n",
    "    print(f\"  Within 5%:  {metrics['Within_5%']:.1f}%\")\n",
    "    print(f\"  Within 10%: {metrics['Within_10%']:.1f}%\")\n",
    "    print(f\"  Within 20%: {metrics['Within_20%']:.1f}%\")\n",
    "    print('='*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Training with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultimodalEnsemble:\n",
    "    \"\"\"\n",
    "    Ensemble model for multimodal real estate price prediction.\n",
    "    Combines XGBoost + LightGBM + CatBoost with Ridge meta-learner.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, use_optuna: bool = True, n_trials: int = 30):\n",
    "        self.use_optuna = use_optuna and OPTUNA_AVAILABLE\n",
    "        self.n_trials = n_trials\n",
    "        self.models = {}\n",
    "        self.best_params = {}\n",
    "        self.ensemble = None\n",
    "        self.scaler = StandardScaler()\n",
    "\n",
    "        # Detect GPU availability\n",
    "        self._detect_gpu()\n",
    "\n",
    "    def _detect_gpu(self):\n",
    "        \"\"\"Detect GPU availability for boosting models\"\"\"\n",
    "        self.gpu_available = False\n",
    "\n",
    "        if TORCH_AVAILABLE and torch.cuda.is_available():\n",
    "            self.gpu_available = True\n",
    "            print(\"GPU detected - enabling GPU acceleration for boosting models\")\n",
    "\n",
    "    def _get_xgb_params(self, trial: Optional['optuna.Trial'] = None) -> Dict:\n",
    "        \"\"\"Get XGBoost parameters (with optional Optuna tuning)\"\"\"\n",
    "        if trial is not None:\n",
    "            params = {\n",
    "                'n_estimators': trial.suggest_int('xgb_n_estimators', 100, 1000),\n",
    "                'max_depth': trial.suggest_int('xgb_max_depth', 3, 12),\n",
    "                'learning_rate': trial.suggest_float('xgb_learning_rate', 0.01, 0.3, log=True),\n",
    "                'subsample': trial.suggest_float('xgb_subsample', 0.6, 1.0),\n",
    "                'colsample_bytree': trial.suggest_float('xgb_colsample_bytree', 0.6, 1.0),\n",
    "                'min_child_weight': trial.suggest_int('xgb_min_child_weight', 1, 10),\n",
    "                'reg_alpha': trial.suggest_float('xgb_reg_alpha', 1e-4, 10, log=True),\n",
    "                'reg_lambda': trial.suggest_float('xgb_reg_lambda', 1e-4, 10, log=True),\n",
    "            }\n",
    "        else:\n",
    "            # Default params from previous Optuna runs\n",
    "            params = {\n",
    "                'n_estimators': 907,\n",
    "                'max_depth': 10,\n",
    "                'learning_rate': 0.0147,\n",
    "                'subsample': 0.893,\n",
    "                'colsample_bytree': 0.691,\n",
    "                'min_child_weight': 5,\n",
    "                'reg_alpha': 0.00157,\n",
    "                'reg_lambda': 5.27e-05,\n",
    "            }\n",
    "\n",
    "        # Add GPU params if available\n",
    "        if self.gpu_available:\n",
    "            params['device'] = 'cuda'\n",
    "            params['tree_method'] = 'hist'\n",
    "\n",
    "        params['random_state'] = config.RANDOM_STATE\n",
    "        params['n_jobs'] = -1\n",
    "\n",
    "        return params\n",
    "\n",
    "    def _get_lgb_params(self, trial: Optional['optuna.Trial'] = None) -> Dict:\n",
    "        \"\"\"Get LightGBM parameters\"\"\"\n",
    "        if trial is not None:\n",
    "            params = {\n",
    "                'n_estimators': trial.suggest_int('lgb_n_estimators', 100, 1000),\n",
    "                'max_depth': trial.suggest_int('lgb_max_depth', 3, 12),\n",
    "                'learning_rate': trial.suggest_float('lgb_learning_rate', 0.01, 0.3, log=True),\n",
    "                'num_leaves': trial.suggest_int('lgb_num_leaves', 20, 100),\n",
    "                'subsample': trial.suggest_float('lgb_subsample', 0.6, 1.0),\n",
    "                'colsample_bytree': trial.suggest_float('lgb_colsample_bytree', 0.6, 1.0),\n",
    "            }\n",
    "        else:\n",
    "            params = {\n",
    "                'n_estimators': 755,\n",
    "                'max_depth': 11,\n",
    "                'learning_rate': 0.075,\n",
    "                'num_leaves': 50,\n",
    "                'subsample': 0.963,\n",
    "                'colsample_bytree': 0.609,\n",
    "            }\n",
    "\n",
    "        if self.gpu_available:\n",
    "            params['device'] = 'gpu'\n",
    "\n",
    "        params['random_state'] = config.RANDOM_STATE\n",
    "        params['n_jobs'] = -1\n",
    "        params['verbose'] = -1\n",
    "\n",
    "        return params\n",
    "\n",
    "    def _get_cat_params(self, trial: Optional['optuna.Trial'] = None) -> Dict:\n",
    "        \"\"\"Get CatBoost parameters\"\"\"\n",
    "        if trial is not None:\n",
    "            params = {\n",
    "                'iterations': trial.suggest_int('cat_iterations', 100, 1000),\n",
    "                'depth': trial.suggest_int('cat_depth', 4, 10),\n",
    "                'learning_rate': trial.suggest_float('cat_learning_rate', 0.01, 0.3, log=True),\n",
    "                'l2_leaf_reg': trial.suggest_float('cat_l2_leaf_reg', 0.1, 10, log=True),\n",
    "            }\n",
    "        else:\n",
    "            params = {\n",
    "                'iterations': 368,\n",
    "                'depth': 8,\n",
    "                'learning_rate': 0.216,\n",
    "                'l2_leaf_reg': 0.825,\n",
    "            }\n",
    "\n",
    "        if self.gpu_available:\n",
    "            params['task_type'] = 'GPU'\n",
    "\n",
    "        params['random_state'] = config.RANDOM_STATE\n",
    "        params['verbose'] = 0\n",
    "\n",
    "        return params\n",
    "\n",
    "    def _objective(self, trial: 'optuna.Trial', X: np.ndarray, y: np.ndarray) -> float:\n",
    "        \"\"\"Optuna objective function for hyperparameter tuning\"\"\"\n",
    "        # Get parameters\n",
    "        xgb_params = self._get_xgb_params(trial)\n",
    "        lgb_params = self._get_lgb_params(trial)\n",
    "        cat_params = self._get_cat_params(trial)\n",
    "\n",
    "        # Create models\n",
    "        xgb = XGBRegressor(**xgb_params)\n",
    "        lgb = LGBMRegressor(**lgb_params)\n",
    "        cat = CatBoostRegressor(**cat_params)\n",
    "\n",
    "        # Cross-validation\n",
    "        kf = KFold(n_splits=3, shuffle=True, random_state=config.RANDOM_STATE)\n",
    "        scores = []\n",
    "\n",
    "        for train_idx, val_idx in kf.split(X):\n",
    "            X_train, X_val = X[train_idx], X[val_idx]\n",
    "            y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "            # Train models\n",
    "            xgb.fit(X_train, y_train)\n",
    "            lgb.fit(X_train, y_train)\n",
    "            cat.fit(X_train, y_train)\n",
    "\n",
    "            # Ensemble prediction (simple average)\n",
    "            pred = (xgb.predict(X_val) + lgb.predict(X_val) + cat.predict(X_val)) / 3\n",
    "\n",
    "            mae = mean_absolute_error(y_val, pred)\n",
    "            scores.append(mae)\n",
    "\n",
    "        return np.mean(scores)\n",
    "\n",
    "    def tune_hyperparameters(self, X: np.ndarray, y: np.ndarray):\n",
    "        \"\"\"Run Optuna hyperparameter tuning\"\"\"\n",
    "        print(f\"\\nRunning Optuna tuning ({self.n_trials} trials)...\")\n",
    "\n",
    "        study = optuna.create_study(direction='minimize')\n",
    "        study.optimize(\n",
    "            lambda trial: self._objective(trial, X, y),\n",
    "            n_trials=self.n_trials,\n",
    "            show_progress_bar=True\n",
    "        )\n",
    "\n",
    "        self.best_params = study.best_params\n",
    "        print(f\"Best MAE: ${study.best_value:.2f}/m\u00b2\")\n",
    "\n",
    "        return self\n",
    "\n",
    "    def fit(self, X: np.ndarray, y: np.ndarray) -> 'MultimodalEnsemble':\n",
    "        \"\"\"Fit the ensemble model\"\"\"\n",
    "        print(\"\\nTraining ensemble model...\")\n",
    "\n",
    "        # Scale features\n",
    "        X_scaled = self.scaler.fit_transform(X)\n",
    "\n",
    "        # Optuna tuning if enabled\n",
    "        if self.use_optuna:\n",
    "            self.tune_hyperparameters(X_scaled, y)\n",
    "\n",
    "        # Create models with best/default params\n",
    "        xgb_params = self._get_xgb_params()\n",
    "        lgb_params = self._get_lgb_params()\n",
    "        cat_params = self._get_cat_params()\n",
    "\n",
    "        # Update with Optuna params if available\n",
    "        for key, value in self.best_params.items():\n",
    "            if key.startswith('xgb_'):\n",
    "                xgb_params[key[4:]] = value\n",
    "            elif key.startswith('lgb_'):\n",
    "                lgb_params[key[4:]] = value\n",
    "            elif key.startswith('cat_'):\n",
    "                cat_params[key[4:]] = value\n",
    "\n",
    "        # Create estimators\n",
    "        estimators = [\n",
    "            ('xgb', XGBRegressor(**xgb_params)),\n",
    "            ('lgb', LGBMRegressor(**lgb_params)),\n",
    "            ('cat', CatBoostRegressor(**cat_params)),\n",
    "        ]\n",
    "\n",
    "        # Stacking ensemble\n",
    "        self.ensemble = StackingRegressor(\n",
    "            estimators=estimators,\n",
    "            final_estimator=Ridge(alpha=1.0),\n",
    "            cv=config.CV_FOLDS,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "\n",
    "        print(\"Fitting stacking ensemble...\")\n",
    "        self.ensemble.fit(X_scaled, y)\n",
    "\n",
    "        # Store individual models for feature importance\n",
    "        self.models = {name: model for name, model in estimators}\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Make predictions\"\"\"\n",
    "        X_scaled = self.scaler.transform(X)\n",
    "        return self.ensemble.predict(X_scaled)\n",
    "\n",
    "    def get_feature_importance(self, feature_names: List[str]) -> pd.DataFrame:\n",
    "        \"\"\"Get feature importance from XGBoost model\"\"\"\n",
    "        xgb_model = self.ensemble.named_estimators_['xgb']\n",
    "        importance = xgb_model.feature_importances_\n",
    "\n",
    "        df = pd.DataFrame({\n",
    "            'feature': feature_names,\n",
    "            'importance': importance\n",
    "        }).sort_values('importance', ascending=False)\n",
    "\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Main Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training_pipeline(\n",
    "    use_images: bool = True,\n",
    "    use_optuna: bool = True,\n",
    "    n_optuna_trials: int = 30\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    Main training pipeline for multimodal model.\n",
    "\n",
    "    Args:\n",
    "        use_images: Whether to include image features\n",
    "        use_optuna: Whether to use Optuna for hyperparameter tuning\n",
    "        n_optuna_trials: Number of Optuna trials\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with results and trained models\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "\n",
    "    # 1. Load data\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\" MULTIMODAL REAL ESTATE PRICE PREDICTION\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    df = load_data()\n",
    "\n",
    "    # 2. Filter valid listings\n",
    "    # Need price and coordinates\n",
    "    df = df[df[config.TARGET_COL].notna()].copy()\n",
    "    df = df[df[config.TARGET_COL] > 0].copy()\n",
    "\n",
    "    # Remove outliers (below 1st and above 99th percentile)\n",
    "    q01 = df[config.TARGET_COL].quantile(0.01)\n",
    "    q99 = df[config.TARGET_COL].quantile(0.99)\n",
    "    df = df[(df[config.TARGET_COL] >= q01) & (df[config.TARGET_COL] <= q99)]\n",
    "\n",
    "    print(f\"Valid listings: {len(df)}\")\n",
    "\n",
    "    # 3. Train/test split\n",
    "    train_df, test_df = train_test_split(\n",
    "        df,\n",
    "        test_size=config.TEST_SIZE,\n",
    "        random_state=config.RANDOM_STATE\n",
    "    )\n",
    "    print(f\"Train: {len(train_df)}, Test: {len(test_df)}\")\n",
    "\n",
    "    # 4. Feature engineering\n",
    "    print(\"\\n--- Tabular Feature Engineering ---\")\n",
    "    feature_engineer = TabularFeatureEngineer()\n",
    "\n",
    "    train_df = feature_engineer.fit_transform(train_df, is_train=True)\n",
    "    test_df = feature_engineer.fit_transform(test_df, is_train=False)\n",
    "\n",
    "    feature_cols = feature_engineer.get_feature_columns()\n",
    "\n",
    "    # Ensure all feature columns exist\n",
    "    for col in feature_cols:\n",
    "        if col not in train_df.columns:\n",
    "            train_df[col] = 0\n",
    "        if col not in test_df.columns:\n",
    "            test_df[col] = 0\n",
    "\n",
    "    X_train_tabular = train_df[feature_cols].values\n",
    "    X_test_tabular = test_df[feature_cols].values\n",
    "    y_train = train_df[config.TARGET_COL].values\n",
    "    y_test = test_df[config.TARGET_COL].values\n",
    "\n",
    "    print(f\"Tabular features: {len(feature_cols)}\")\n",
    "\n",
    "    # 5. Image features (optional)\n",
    "    if use_images and TORCH_AVAILABLE:\n",
    "        print(\"\\n--- Image Feature Extraction ---\")\n",
    "\n",
    "        # Get listing IDs\n",
    "        id_col = 'listing_id' if 'listing_id' in train_df.columns else 'id'\n",
    "        train_ids = train_df[id_col].astype(str).tolist()\n",
    "        test_ids = test_df[id_col].astype(str).tolist()\n",
    "\n",
    "        # Extract embeddings\n",
    "        img_extractor = ImageFeatureExtractor(\n",
    "            pca_components=config.PCA_COMPONENTS,\n",
    "            batch_size=config.BATCH_SIZE\n",
    "        )\n",
    "\n",
    "        train_embeddings = img_extractor.extract_all_listings(\n",
    "            train_ids,\n",
    "            config.IMAGES_DIR\n",
    "        )\n",
    "        test_embeddings = img_extractor.extract_all_listings(\n",
    "            test_ids,\n",
    "            config.IMAGES_DIR\n",
    "        )\n",
    "\n",
    "        # Check how many listings have images\n",
    "        train_has_images = (train_embeddings.sum(axis=1) != 0).sum()\n",
    "        test_has_images = (test_embeddings.sum(axis=1) != 0).sum()\n",
    "        print(f\"Listings with images - Train: {train_has_images}/{len(train_ids)}, Test: {test_has_images}/{len(test_ids)}\")\n",
    "\n",
    "        # PCA reduction\n",
    "        train_img_features = img_extractor.fit_transform_pca(train_embeddings)\n",
    "        test_img_features = img_extractor.transform_pca(test_embeddings)\n",
    "\n",
    "        # Combine tabular + image features\n",
    "        X_train = np.hstack([X_train_tabular, train_img_features])\n",
    "        X_test = np.hstack([X_test_tabular, test_img_features])\n",
    "\n",
    "        # Update feature names\n",
    "        img_feature_names = [f'img_pca_{i}' for i in range(config.PCA_COMPONENTS)]\n",
    "        all_feature_names = feature_cols + img_feature_names\n",
    "\n",
    "        print(f\"Total features: {X_train.shape[1]} ({len(feature_cols)} tabular + {config.PCA_COMPONENTS} image)\")\n",
    "\n",
    "        results['img_extractor'] = img_extractor\n",
    "    else:\n",
    "        X_train = X_train_tabular\n",
    "        X_test = X_test_tabular\n",
    "        all_feature_names = feature_cols\n",
    "        print(\"Image features disabled\")\n",
    "\n",
    "    # Handle NaN values\n",
    "    X_train = np.nan_to_num(X_train, nan=0.0)\n",
    "    X_test = np.nan_to_num(X_test, nan=0.0)\n",
    "\n",
    "    # 6. Train model\n",
    "    print(\"\\n--- Model Training ---\")\n",
    "    model = MultimodalEnsemble(\n",
    "        use_optuna=use_optuna,\n",
    "        n_trials=n_optuna_trials\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # 7. Evaluate\n",
    "    print(\"\\n--- Evaluation ---\")\n",
    "\n",
    "    # Training metrics\n",
    "    train_pred = model.predict(X_train)\n",
    "    train_metrics = calculate_metrics(y_train, train_pred)\n",
    "    print_metrics(train_metrics, \"TRAINING SET\")\n",
    "\n",
    "    # Test metrics\n",
    "    test_pred = model.predict(X_test)\n",
    "    test_metrics = calculate_metrics(y_test, test_pred)\n",
    "    print_metrics(test_metrics, \"TEST SET\")\n",
    "\n",
    "    # 8. Feature importance\n",
    "    print(\"\\n--- Top 15 Features ---\")\n",
    "    importance_df = model.get_feature_importance(all_feature_names)\n",
    "    print(importance_df.head(15).to_string(index=False))\n",
    "\n",
    "    # Store results\n",
    "    results.update({\n",
    "        'model': model,\n",
    "        'feature_engineer': feature_engineer,\n",
    "        'train_metrics': train_metrics,\n",
    "        'test_metrics': test_metrics,\n",
    "        'feature_importance': importance_df,\n",
    "        'feature_names': all_feature_names,\n",
    "        'predictions': {\n",
    "            'y_train': y_train,\n",
    "            'y_test': y_test,\n",
    "            'train_pred': train_pred,\n",
    "            'test_pred': test_pred,\n",
    "        }\n",
    "    })\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Run Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 1: Tabular only (baseline)\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\" EXPERIMENT 1: TABULAR FEATURES ONLY (BASELINE)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "results_tabular = run_training_pipeline(\n",
    "    use_images=False,\n",
    "    use_optuna=True,\n",
    "    n_optuna_trials=config.N_OPTUNA_TRIALS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 2: Tabular + Images (multimodal)\n",
    "if TORCH_AVAILABLE:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\" EXPERIMENT 2: MULTIMODAL (TABULAR + IMAGES)\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    results_multimodal = run_training_pipeline(\n",
    "        use_images=True,\n",
    "        use_optuna=True,\n",
    "        n_optuna_trials=config.N_OPTUNA_TRIALS\n",
    "    )\n",
    "else:\n",
    "    print(\"Skipping multimodal experiment - PyTorch not available\")\n",
    "    results_multimodal = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Results Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_results(tabular_results: Dict, multimodal_results: Optional[Dict]):\n",
    "    \"\"\"Compare tabular vs multimodal results\"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\" RESULTS COMPARISON\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    tab = tabular_results['test_metrics']\n",
    "\n",
    "    print(f\"\\n{'Metric':<15} {'Tabular':>12}\", end='')\n",
    "    if multimodal_results:\n",
    "        mm = multimodal_results['test_metrics']\n",
    "        print(f\" {'Multimodal':>12} {'Change':>12}\")\n",
    "    else:\n",
    "        print()\n",
    "\n",
    "    print(\"-\" * 55)\n",
    "\n",
    "    metrics = ['MAE', 'RMSE', 'R2', 'MedAPE', 'Within_10%']\n",
    "    for metric in metrics:\n",
    "        print(f\"{metric:<15} {tab[metric]:>12.2f}\", end='')\n",
    "        if multimodal_results:\n",
    "            change = mm[metric] - tab[metric]\n",
    "            pct = change / tab[metric] * 100 if tab[metric] != 0 else 0\n",
    "            sign = '+' if change > 0 else ''\n",
    "            print(f\" {mm[metric]:>12.2f} {sign}{pct:>10.1f}%\")\n",
    "        else:\n",
    "            print()\n",
    "\n",
    "    if multimodal_results:\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\" SUMMARY\")\n",
    "        print(\"=\"*70)\n",
    "\n",
    "        mae_improvement = (tab['MAE'] - mm['MAE']) / tab['MAE'] * 100\n",
    "        r2_improvement = (mm['R2'] - tab['R2']) / tab['R2'] * 100\n",
    "        medape_improvement = (tab['MedAPE'] - mm['MedAPE']) / tab['MedAPE'] * 100\n",
    "\n",
    "        print(f\"MAE improved by: {mae_improvement:.1f}%\")\n",
    "        print(f\"R\u00b2 improved by: {r2_improvement:.1f}%\")\n",
    "        print(f\"MedAPE improved by: {medape_improvement:.1f}%\")\n",
    "\n",
    "        # Check if images helped\n",
    "        if mae_improvement > 0:\n",
    "            print(\"\\n\u2705 Image features IMPROVED the model!\")\n",
    "        else:\n",
    "            print(\"\\n\u26a0\ufe0f Image features did not improve the model\")\n",
    "            print(\"   Possible reasons:\")\n",
    "            print(\"   - Not enough images per listing\")\n",
    "            print(\"   - Image quality issues\")\n",
    "            print(\"   - Features already capture property quality\")\n",
    "\n",
    "\n",
    "compare_results(results_tabular, results_multimodal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(results: Dict, title: str = \"Model Results\"):\n",
    "    \"\"\"Plot prediction analysis\"\"\"\n",
    "    y_test = results['predictions']['y_test']\n",
    "    y_pred = results['predictions']['test_pred']\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "    # 1. Actual vs Predicted\n",
    "    ax = axes[0]\n",
    "    ax.scatter(y_test, y_pred, alpha=0.5, s=10)\n",
    "    ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "    ax.set_xlabel('Actual Price ($/m\u00b2)')\n",
    "    ax.set_ylabel('Predicted Price ($/m\u00b2)')\n",
    "    ax.set_title(f'{title}: Actual vs Predicted')\n",
    "\n",
    "    # 2. Error distribution\n",
    "    ax = axes[1]\n",
    "    errors = y_test - y_pred\n",
    "    ax.hist(errors, bins=50, edgecolor='black', alpha=0.7)\n",
    "    ax.axvline(0, color='r', linestyle='--', lw=2)\n",
    "    ax.set_xlabel('Prediction Error ($/m\u00b2)')\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.set_title('Error Distribution')\n",
    "\n",
    "    # 3. Percentage error distribution\n",
    "    ax = axes[2]\n",
    "    pct_errors = np.abs((y_test - y_pred) / y_test) * 100\n",
    "    ax.hist(pct_errors, bins=50, edgecolor='black', alpha=0.7, range=(0, 50))\n",
    "    ax.axvline(10, color='r', linestyle='--', lw=2, label='10% threshold')\n",
    "    ax.set_xlabel('Absolute Percentage Error (%)')\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.set_title('APE Distribution')\n",
    "    ax.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('results_analysis.png', dpi=150)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Plot tabular results\n",
    "plot_results(results_tabular, \"Tabular Model\")\n",
    "\n",
    "# Plot multimodal results if available\n",
    "if results_multimodal:\n",
    "    plot_results(results_multimodal, \"Multimodal Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importance(results: Dict, top_n: int = 20):\n",
    "    \"\"\"Plot feature importance\"\"\"\n",
    "    importance_df = results['feature_importance'].head(top_n)\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.barh(importance_df['feature'], importance_df['importance'])\n",
    "    plt.xlabel('Importance')\n",
    "    plt.title(f'Top {top_n} Feature Importance')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('feature_importance.png', dpi=150)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_feature_importance(results_tabular)\n",
    "\n",
    "if results_multimodal:\n",
    "    plot_feature_importance(results_multimodal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions\n",
    "results_df = pd.DataFrame({\n",
    "    'actual': results_tabular['predictions']['y_test'],\n",
    "    'tabular_pred': results_tabular['predictions']['test_pred'],\n",
    "})\n",
    "\n",
    "if results_multimodal:\n",
    "    results_df['multimodal_pred'] = results_multimodal['predictions']['test_pred']\n",
    "\n",
    "results_df['tabular_error'] = results_df['actual'] - results_df['tabular_pred']\n",
    "results_df['tabular_ape'] = np.abs(results_df['tabular_error'] / results_df['actual']) * 100\n",
    "\n",
    "if results_multimodal:\n",
    "    results_df['multimodal_error'] = results_df['actual'] - results_df['multimodal_pred']\n",
    "    results_df['multimodal_ape'] = np.abs(results_df['multimodal_error'] / results_df['actual']) * 100\n",
    "\n",
    "results_df.to_csv('predictions.csv', index=False)\n",
    "print(\"Predictions saved to predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\" FINAL SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nDataset: {len(df)} listings\")\n",
    "print(f\"Features: {len(results_tabular['feature_names'])} tabular\", end='')\n",
    "if results_multimodal:\n",
    "    print(f\" + {config.PCA_COMPONENTS} image = {len(results_multimodal['feature_names'])} total\")\n",
    "else:\n",
    "    print()\n",
    "\n",
    "print(f\"\\nTabular Model:\")\n",
    "print(f\"  MAE: ${results_tabular['test_metrics']['MAE']:.2f}/m\u00b2\")\n",
    "print(f\"  R\u00b2: {results_tabular['test_metrics']['R2']:.4f}\")\n",
    "print(f\"  MedAPE: {results_tabular['test_metrics']['MedAPE']:.2f}%\")\n",
    "\n",
    "if results_multimodal:\n",
    "    print(f\"\\nMultimodal Model:\")\n",
    "    print(f\"  MAE: ${results_multimodal['test_metrics']['MAE']:.2f}/m\u00b2\")\n",
    "    print(f\"  R\u00b2: {results_multimodal['test_metrics']['R2']:.4f}\")\n",
    "    print(f\"  MedAPE: {results_multimodal['test_metrics']['MedAPE']:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}